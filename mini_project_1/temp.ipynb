{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a0a7b2-1577-473e-9396-49c78d13962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_dataset(dataset):\n",
    "    \"\"\"Compute the mean of a numerical, multidimensional dataset.\"\"\"\n",
    "    sum_data = [sum(column) for column in zip(*dataset)]\n",
    "    means = [sum_val / len(dataset) for sum_val in sum_data]\n",
    "    return means\n",
    "\n",
    "def sample_covariance(vector1, vector2):\n",
    "    \"\"\"Compute the sample covariance between two attributes.\"\"\"\n",
    "    mean1 = sum(vector1) / len(vector1)\n",
    "    mean2 = sum(vector2) / len(vector2)\n",
    "    covariance = sum((a - mean1) * (b - mean2) for a, b in zip(vector1, vector2)) / (len(vector1) - 1)\n",
    "    return covariance\n",
    "\n",
    "def correlation(vector1, vector2):\n",
    "    \"\"\"Compute the correlation between two attributes.\"\"\"\n",
    "    mean1 = sum(vector1) / len(vector1)\n",
    "    mean2 = sum(vector2) / len(vector2)\n",
    "    std_dev1 = (sum((x - mean1) ** 2 for x in vector1) / (len(vector1) - 1)) ** 0.5\n",
    "    std_dev2 = (sum((x - mean2) ** 2 for x in vector2) / (len(vector2) - 1)) ** 0.5\n",
    "    covariance = sum((a - mean1) * (b - mean2) for a, b in zip(vector1, vector2)) / (len(vector1) - 1)\n",
    "    correlation = covariance / (std_dev1 * std_dev2)\n",
    "    return correlation\n",
    "\n",
    "def range_normalization(dataset):\n",
    "    \"\"\"Normalize the attributes in a dataset using range normalization.\"\"\"\n",
    "    mins = [min(column) for column in zip(*dataset)]\n",
    "    maxs = [max(column) for column in zip(*dataset)]\n",
    "    normalized_data = [[(x - min_val) / (max_val - min_val) for x, min_val, max_val in zip(row, mins, maxs)] for row in dataset]\n",
    "    return normalized_data\n",
    "\n",
    "def standard_normalization(dataset):\n",
    "    \"\"\"Normalize the attributes in a dataset using standard normalization.\"\"\"\n",
    "    means = [sum(column) / len(dataset) for column in zip(*dataset)]\n",
    "    std_devs = [(sum((x - mean) ** 2 for x in column) / len(dataset)) ** 0.5 for mean, column in zip(means, zip(*dataset))]\n",
    "    standardized_data = [[(x - mean) / std_dev for x, mean, std_dev in zip(row, means, std_devs)] for row in dataset]\n",
    "    return standardized_data\n",
    "\n",
    "def covariance_matrix(dataset):\n",
    "    \"\"\"Compute the covariance matrix of a dataset.\"\"\"\n",
    "    means = [sum(column) / len(dataset) for column in zip(*dataset)]\n",
    "    cov_matrix = [[sum((row[i] - means[i]) * (row[j] - means[j]) for row in dataset) / (len(dataset) - 1) for j in range(len(means))] for i in range(len(means))]\n",
    "    return cov_matrix\n",
    "\n",
    "def label_encode(dataset):\n",
    "    \"\"\"Label-encode a two-dimensional categorical data array.\"\"\"\n",
    "    unique_vals = {val for row in dataset for val in row}\n",
    "    val_to_int = {val: i for i, val in enumerate(unique_vals)}\n",
    "    encoded_data = [[val_to_int[val] for val in row] for row in dataset]\n",
    "    return encoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c7f69f-3cfb-4def-8e33-e10880530a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        reader = csv.DictReader(file, delimiter=';')\n",
    "        data = [row for row in reader]\n",
    "    return data\n",
    "\n",
    "def one_hot_encode(data):\n",
    "    # Identify categorical columns\n",
    "    categorical_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
    "    encoded_data = []\n",
    "    encodings = {col: defaultdict(int) for col in categorical_cols}\n",
    "\n",
    "    # Generate encodings\n",
    "    for row in data:\n",
    "        for col in categorical_cols:\n",
    "            encodings[col][row[col]] += 1\n",
    "    \n",
    "    # Convert encodings to index-based encoding\n",
    "    for col, mapping in encodings.items():\n",
    "        encodings[col] = {key: idx for idx, key in enumerate(mapping)}\n",
    "    \n",
    "    # Encode data\n",
    "    for row in data:\n",
    "        new_row = row.copy()\n",
    "        for col in categorical_cols:\n",
    "            for val, idx in encodings[col].items():\n",
    "                new_row[f\"{col}_{val}\"] = 1 if row[col] == val else 0\n",
    "            del new_row[col]\n",
    "        encoded_data.append(new_row)\n",
    "    \n",
    "    return encoded_data, encodings\n",
    "\n",
    "data_path = 'student/student-mat.csv'\n",
    "data = load_data(data_path)\n",
    "encoded_data, encodings = one_hot_encode(data)\n",
    "\n",
    "# Convert the list of dictionaries to a list of lists for numerical processing\n",
    "def dict_to_list(data, encodings):\n",
    "    header = sorted(list(data[0].keys()))\n",
    "    return [header] + [[row[col] for col in header] for row in data]\n",
    "\n",
    "# Convert encoded data to a list of lists\n",
    "encoded_data_list = dict_to_list(encoded_data, encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b3cd3b8-7b25-4bcd-96d1-219e39a25582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `encoded_data_filled` from the previous step is the input data\n",
    "def convert_to_numeric(data):\n",
    "    # Skip header and convert data rows to numeric values\n",
    "    return [[float(value) for value in row] for row in data[1:]]\n",
    "\n",
    "def compute_multivariate_mean(data):\n",
    "    numeric_data = convert_to_numeric(data)\n",
    "    return mean_of_dataset(numeric_data)\n",
    "\n",
    "def compute_covariance_matrix(data):\n",
    "    numeric_data = convert_to_numeric(data)\n",
    "    return covariance_matrix(numeric_data)\n",
    "\n",
    "# Compute multivariate mean\n",
    "multivariate_mean = compute_multivariate_mean(encoded_data_list)\n",
    "# print(\"Multivariate Mean:\", multivariate_mean)\n",
    "\n",
    "# Compute covariance matrix\n",
    "cov_matrix = compute_covariance_matrix(encoded_data_list)\n",
    "# print(\"Covariance Matrix:\", cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27ad721-5567-4bae-92d1-9bbdc593ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_scatter_pairs(data, pairs):\n",
    "    numeric_data = convert_to_numeric(data)\n",
    "    header = data[0]\n",
    "\n",
    "    for pair in pairs:\n",
    "        idx1, idx2 = header.index(pair[0]), header.index(pair[1])\n",
    "        x = [row[idx1] for row in numeric_data]\n",
    "        y = [row[idx2] for row in numeric_data]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.scatter(x, y)\n",
    "        plt.title(f\"Scatter Plot: {pair[0]} vs {pair[1]}\")\n",
    "        plt.xlabel(pair[0])\n",
    "        plt.ylabel(pair[1])\n",
    "        plt.show()\n",
    "\n",
    "# Define pairs for scatter plots\n",
    "pairs = [(\"age\", \"absences\"), (\"G1\", \"G2\"), (\"studytime\", \"failures\"), (\"Dalc\", \"Walc\"), (\"freetime\", \"goout\")]\n",
    "\n",
    "# Plot scatter pairs\n",
    "# plot_scatter_pairs(encoded_data_list, pairs)  #uncomment to see graphs :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea25cd8-f781-456c-b9dc-d5b4b8c9623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatest Sample Covariance: 0.00014457366831587798\n"
     ]
    }
   ],
   "source": [
    "def find_greatest_sample_covariance(data):\n",
    "    numeric_data = convert_to_numeric(data)\n",
    "    range_normalized_data = range_normalization(numeric_data)\n",
    "    # Assume you've identified two attributes of interest; you would compute their indices and use them here\n",
    "    # For demonstration, let's say indices 0 and 1 represent those attributes\n",
    "    cov = sample_covariance([row[0] for row in range_normalized_data], [row[1] for row in range_normalized_data])\n",
    "    return cov\n",
    "\n",
    "# Example usage\n",
    "greatest_covariance = find_greatest_sample_covariance(encoded_data_list)\n",
    "print(\"Greatest Sample Covariance:\", greatest_covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74f9caa6-ef55-48d1-9d7e-b202c72bc36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatest Correlation: -1.0000000000000002 between attributes (22, 23)\n"
     ]
    }
   ],
   "source": [
    "def z_score_normalize(data):\n",
    "    numeric_data = convert_to_numeric(data)\n",
    "    return standard_normalization(numeric_data)\n",
    "\n",
    "def find_greatest_correlation(data):\n",
    "    normalized_data = z_score_normalize(data)\n",
    "    n = len(normalized_data[0])\n",
    "    greatest_correlation = 0\n",
    "    pair = (0, 1)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            corr = correlation([row[i] for row in normalized_data], [row[j] for row in normalized_data])\n",
    "            if abs(corr) > abs(greatest_correlation):\n",
    "                greatest_correlation = corr\n",
    "                pair = (i, j)\n",
    "    return pair, greatest_correlation\n",
    "\n",
    "normalized_data = z_score_normalize(encoded_data_list)\n",
    "pair, greatest_correlation = find_greatest_correlation(encoded_data_list)\n",
    "print(f\"Greatest Correlation: {greatest_correlation} between attributes {pair}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8911fb6-900d-4d39-8a4d-cce134edaa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Correlation: -8.102234019729828e-05 between attributes (15, 46)\n"
     ]
    }
   ],
   "source": [
    "def find_smallest_correlation(data):\n",
    "    normalized_data = z_score_normalize(data)\n",
    "    n = len(normalized_data[0])\n",
    "    smallest_correlation = 1  # Start with the maximum possible correlation\n",
    "    pair = (0, 1)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            corr = correlation([row[i] for row in normalized_data], [row[j] for row in normalized_data])\n",
    "            if abs(corr) < abs(smallest_correlation):\n",
    "                smallest_correlation = corr\n",
    "                pair = (i, j)\n",
    "    return pair, smallest_correlation\n",
    "\n",
    "pair, smallest_correlation = find_smallest_correlation(encoded_data_list)\n",
    "print(f\"Smallest Correlation: {smallest_correlation} between attributes {pair}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3e8e768-262e-4396-9aff-61c06997055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature pairs with correlation >= 0.5: 20\n"
     ]
    }
   ],
   "source": [
    "def count_high_correlations(data, threshold=0.5):\n",
    "    normalized_data = z_score_normalize(data)\n",
    "    n = len(normalized_data[0])\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            corr = correlation([row[i] for row in normalized_data], [row[j] for row in normalized_data])\n",
    "            if abs(corr) >= threshold:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "high_corr_count = count_high_correlations(encoded_data_list)\n",
    "print(f\"Number of feature pairs with correlation >= 0.5: {high_corr_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04edc2a8-2a65-4367-912f-e02e795863ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature pairs with negative sample covariance: 884\n"
     ]
    }
   ],
   "source": [
    "def count_negative_covariances(data):\n",
    "    numeric_data = convert_to_numeric(data)\n",
    "    n = len(numeric_data[0])\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            cov = sample_covariance([row[i] for row in numeric_data], [row[j] for row in numeric_data])\n",
    "            if cov < 0:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "negative_cov_count = count_negative_covariances(encoded_data_list)\n",
    "print(f\"Number of feature pairs with negative sample covariance: {negative_cov_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b88fa041-19aa-4cd9-8c22-2e3ae5c01e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Variance of the data: 130.42906894557603\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_variance(data):\n",
    "    cov_matrix = compute_covariance_matrix(data)\n",
    "    total_variance = sum(cov_matrix[i][i] for i in range(len(cov_matrix)))\n",
    "    return total_variance\n",
    "\n",
    "total_variance = calculate_total_variance(encoded_data_list)\n",
    "print(f\"Total Variance of the data: {total_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d93541d-0dd0-414f-9f11-50095db640e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Variance of the top 5 features: 112.13807106598983\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_variance_top_features(data, top_n=5):\n",
    "    numeric_data = convert_to_numeric(data)\n",
    "    variances = [sample_variance([row[i] for row in numeric_data]) for i in range(len(numeric_data[0]))]\n",
    "    top_variances = sorted(variances, reverse=True)[:top_n]\n",
    "    return sum(top_variances)\n",
    "\n",
    "# Sample variance function needed for the above code, assuming it's implemented similarly to other statistical functions provided earlier\n",
    "def sample_variance(vector):\n",
    "    mean = sum(vector) / len(vector)\n",
    "    variance = sum((x - mean) ** 2 for x in vector) / (len(vector) - 1)\n",
    "    return variance\n",
    "\n",
    "total_variance_top_features = calculate_total_variance_top_features(encoded_data_list)\n",
    "print(f\"Total Variance of the top 5 features: {total_variance_top_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ff111-8b5e-46df-8651-a383b734e491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
